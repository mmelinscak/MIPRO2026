Comparison of the Segment Anything Model and U-Net-Based Architectures for Retinal Fluid Segmentation Using the AROI Dataset

Abstract â€“ Retinal fluid segmentation from optical coherence tomography (OCT) images is important for diagnosing and monitoring retinal diseases such as neovascular age-related macular degeneration. U-Net-based architectures are the standard for this task, providing accurate results on domain-specific datasets. Recently, foundation models such as the Segment Anything Model (SAM) have emerged as general-purpose segmentation tools that operate in a prompt-based, zero-shot manner, but their performance on challenging medical imaging tasks remains underexplored. This study presents a comparative evaluation of SAM and U-Net-based architectures for retinal fluid segmentation on the AROI dataset, a publicly available benchmark containing multi-class annotations of retinal layers and pathological fluids. SAM is applied in a zero-shot setting using automatically generated box prompts derived from annotated fluid regions. Its performance is compared against U-Net and Attention U-Net models using the Dice coefficient and Intersection over Union (IoU). SAM achieved the best results for intraretinal fluid (IRF) and showed competitive performance on subretinal fluid (SRF), while U-Net-based models were more consistent for pigment epithelial detachment (PED), benefiting from anatomical context learned during training. We analyze the applicability, strengths, and limitations of a general-purpose segmentation model in a clinically challenging OCT scenario and highlight differences relative to specialized medical architectures.
